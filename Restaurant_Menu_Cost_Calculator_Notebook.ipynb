{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/Magentic-AlgoTrading101/blob/main/Restaurant_Menu_Cost_Calculator_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is an Experiment to leverage Multimodal LLM to calculate how much does it cost to dine in Gabicce.\n",
        "The notebook will load images of restaurants menus and i will ask LLM to calculate how much does it cost for a family of 3 and a standard meal to eat in a restaurant in Gabicce Mare (Italy)\n",
        "I have downloaded menu images and stored them on my google drive.\n",
        "I then generate a base64 representation of each image and ask the model to interpret it.\n",
        "\n",
        "The next step will be to extract structured data from the image, load them\n",
        "in a vector store and perform some queries"
      ],
      "metadata": {
        "id": "spEvM_6cA64K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting the drive\n",
        "\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import base64\n",
        "import io\n",
        "from google.colab import drive\n",
        "\n",
        "# --- Step 1: Mount Google Drive ---\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully.\")"
      ],
      "metadata": {
        "id": "aFjXB9VasMH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Define the path to your images in Google Drive ---\n",
        "# IMPORTANT: Update this path to where your images are stored in your Google Drive.\n",
        "# Example: '/content/drive/MyDrive/MyImagesFolder'\n",
        "image_folder_path = '/content/drive/MyDrive/Menus' # <--- UPDATE THIS PATH\n"
      ],
      "metadata": {
        "id": "QQimWSyIsj_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Cell below to generate base64 representation of your images"
      ],
      "metadata": {
        "id": "ZbyUnPOKQwd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell will generat a base64 so that i can embed all the images in my notebook. you dont need to run it for my example, but if you want to load\n",
        "# your own images you will need to\n",
        "# 1. load images in a folder called menus  - see folder on the right\n",
        "# 2. run the cell below that will output a a base64 image\n",
        "# 3. copy the output in each new cell\n",
        "import base64\n",
        "import os\n",
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "# Define the directory where your images are located\n",
        "image_directory = image_folder_path#'menus'\n",
        "\n",
        "# --- Step 1: List all image files in the specified directory ---\n",
        "image_files = []\n",
        "\n",
        "\n",
        "encoded_images = []\n",
        "\n",
        "\n",
        "try:\n",
        "    # Check if the directory exists\n",
        "    if not os.path.exists(image_directory):\n",
        "        print(f\"Error: Directory '{image_directory}' not found in the current Colab session.\")\n",
        "        print(\"Please ensure you have uploaded your 'menus' folder correctly.\")\n",
        "    else:\n",
        "        # Filter for common image extensions\n",
        "        for filename in os.listdir(image_directory):\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp')):\n",
        "                image_files.append(filename)\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No image files found in '{image_directory}'. Please check the folder content.\")\n",
        "    else:\n",
        "        print(f\"Found {len(image_files)} image(s) in '{image_directory}': {', '.join(image_files)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing files: {e}\")\n",
        "\n",
        "# --- Step 2: Process and output Base64 for each found image ---\n",
        "if image_files:\n",
        "    print(\"\\n--- Generating Base64 Markdown for all found images: ---\")\n",
        "    print(\"-----------------------------------------------------------------\")\n",
        "\n",
        "    for selected_filename in image_files:\n",
        "        full_image_path = os.path.join(image_directory, selected_filename)\n",
        "\n",
        "        print(f\"\\nProcessing '{selected_filename}'...\")\n",
        "\n",
        "        # --- Step 3: Read and Base64 encode the selected image ---\n",
        "        try:\n",
        "            with open(full_image_path, 'rb') as img_file:\n",
        "                encoded_string = base64.b64encode(img_file.read()).decode('utf-8')\n",
        "\n",
        "            # Determine MIME type based on file extension\n",
        "            mime_type = \"image/png\" # Default\n",
        "            if selected_filename.lower().endswith(('.jpg', '.jpeg')):\n",
        "                mime_type = \"image/jpeg\"\n",
        "            elif selected_filename.lower().endswith('.gif'):\n",
        "                mime_type = \"image/gif\"\n",
        "            elif selected_filename.lower().endswith('.bmp'):\n",
        "                mime_type = \"image/bmp\"\n",
        "            elif selected_filename.lower().endswith('.webp'):\n",
        "                mime_type = \"image/webp\"\n",
        "\n",
        "            # --- Step 4: Generate Markdown for embedding ---\n",
        "            # You can customize the Alt Text here if needed\n",
        "            alt_text = f\"Image: {selected_filename}\"\n",
        "            markdown_code = f\"![{alt_text}](data:{mime_type};base64,{encoded_string})\"\n",
        "\n",
        "            encoded_images.append((selected_filename, mime_type, encoded_string))\n",
        "\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Image file '{full_image_path}' not found. It might have been deleted.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during encoding or display for '{selected_filename}': {e}\")\n",
        "else:\n",
        "    print(\"\\nNo images available to process. Please upload images to the 'menus' folder.\")\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(encoded_images)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o3-a5DKjCskm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calling model to extract menu from images"
      ],
      "metadata": {
        "id": "J39el84NlD0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import M\n",
        "import base64\n",
        "import requests\n",
        "import json\n",
        "from PIL import Image\n",
        "import io\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- Configuration ---\n",
        "# Replace with your actual Gemini API Key.\n",
        "# In a real environment, you'd load this securely (e.g., from environment variables).\n",
        "# For this Canvas environment, the __api_key__ variable will be provided at runtime.\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY') # Leave this empty, Canvas will inject the API key.\n",
        "GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
        "\n",
        "# --- Helper Function: Image to Base64 ---\n",
        "# --- Function: Extract Menu Items using Gemini API ---\n",
        "def extract_menu_from_image(base64_image_data, prompt_text):\n",
        "    \"\"\"\n",
        "    Calls the Gemini API to extract menu items and prices from an image.\n",
        "    It uses a structured response schema to get JSON output.\n",
        "    \"\"\"\n",
        "    if not base64_image_data:\n",
        "        return {\"error\": \"No image data provided.\"}\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "\n",
        "    # Define the structured schema for the response\n",
        "    response_schema = {\n",
        "        \"type\": \"ARRAY\",\n",
        "        \"items\": {\n",
        "            \"type\": \"OBJECT\",\n",
        "            \"properties\": {\n",
        "                \"item\": {\"type\": \"STRING\"},\n",
        "                \"price\": {\"type\": \"NUMBER\"}\n",
        "            },\n",
        "            \"required\": [\"item\", \"price\"]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt_text},\n",
        "                    {\n",
        "                        \"inlineData\": {\n",
        "                            \"mimeType\": \"image/jpeg\", # Adjust mimeType if you save as PNG\n",
        "                            \"data\": base64_image_data\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"generationConfig\": {\n",
        "            \"responseMimeType\": \"application/json\",\n",
        "            \"responseSchema\": response_schema\n",
        "        }\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(f\"{GEMINI_API_URL}?key={API_KEY}\", headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get('candidates') and result['candidates'][0].get('content') and result['candidates'][0]['content'].get('parts'):\n",
        "            # The API returns the JSON as a string within the 'text' field\n",
        "            json_string = result['candidates'][0]['content']['parts'][0]['text']\n",
        "            # Parse the JSON string into a Python object\n",
        "            parsed_json = json.loads(json_string)\n",
        "            return parsed_json\n",
        "        else:\n",
        "            print(\"Unexpected API response structure:\", result)\n",
        "            return {\"error\": \"Could not extract menu items. Unexpected API response.\"}\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"API request failed: {e}\")\n",
        "        return {\"error\": f\"API request failed: {e}\"}\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Failed to decode JSON response: {e}\")\n",
        "        print(f\"Raw response text: {response.text}\")\n",
        "        return {\"error\": f\"Failed to decode JSON response: {e}\"}\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return {\"error\": f\"An unexpected error occurred: {e}\"}\n",
        "\n",
        "# --- Function: Calculate Meal Cost ---\n",
        "def calculate_meal_cost(extracted_menu, desired_items, num_people, price_increase_percent, coperto_per_person=2.50):\n",
        "    \"\"\"\n",
        "    Calculates the total estimated cost for a meal based on extracted menu prices,\n",
        "    desired items, number of people, and a price increase percentage.\n",
        "    \"\"\"\n",
        "    total_food_cost = 0.0\n",
        "    print(\"\\n--- Calculating Meal Cost ---\")\n",
        "    print(f\"Desired items for {num_people} people:\")\n",
        "\n",
        "    for item_name, quantity in desired_items.items():\n",
        "        found_price = None\n",
        "        # Try to find the item in the extracted menu (case-insensitive, partial match)\n",
        "        for menu_item in extracted_menu:\n",
        "            if item_name.lower() in menu_item['item'].lower():\n",
        "                found_price = menu_item['price']\n",
        "                break\n",
        "\n",
        "        if found_price is not None:\n",
        "            cost_for_item = found_price * quantity\n",
        "            total_food_cost += cost_for_item\n",
        "            print(f\"- {quantity}x {item_name}: €{found_price:.2f} each -> €{cost_for_item:.2f}\")\n",
        "        else:\n",
        "            print(f\"- Warning: '{item_name}' not found in the extracted menu. Skipping this item.\")\n",
        "            # For items not found, we'll use a reasonable average from previous context\n",
        "            # This is a fallback if the OCR/LLM misses something or if the item is generic\n",
        "            if \"patatine fritte\" in item_name.lower():\n",
        "                found_price = 4.50\n",
        "            elif \"insalata\" in item_name.lower():\n",
        "                found_price = 4.50\n",
        "            elif \"primi piatti di pasta\" in item_name.lower() or \"pasta\" in item_name.lower():\n",
        "                found_price = 15.00\n",
        "            elif \"pizza\" in item_name.lower():\n",
        "                found_price = 10.00\n",
        "            else:\n",
        "                found_price = 0.0 # Default to 0 if no reasonable fallback\n",
        "\n",
        "            if found_price > 0:\n",
        "                cost_for_item = found_price * quantity\n",
        "                total_food_cost += cost_for_item\n",
        "                print(f\"  (Using estimated price: €{found_price:.2f} for {item_name} -> €{cost_for_item:.2f})\")\n",
        "\n",
        "\n",
        "    print(f\"\\nSubtotal for food before increase: €{total_food_cost:.2f}\")\n",
        "\n",
        "    # Apply price increase\n",
        "    increased_food_cost = total_food_cost * (1 + price_increase_percent / 100)\n",
        "    print(f\"Subtotal for food after {price_increase_percent}% increase: €{increased_food_cost:.2f}\")\n",
        "\n",
        "    # Add coperto\n",
        "    total_coperto_cost = coperto_per_person * num_people\n",
        "    print(f\"Coperto ({coperto_per_person:.2f} per person for {num_people} people): €{total_coperto_cost:.2f}\")\n",
        "\n",
        "    final_total_cost = increased_food_cost + total_coperto_cost\n",
        "    print(f\"\\nEstimated total cost for {num_people} people: €{final_total_cost:.2f}\")\n",
        "\n",
        "    return final_total_cost\n",
        "\n",
        "# --- Main Execution ---\n",
        "# --- Step 1: Prepare the Image ---\n",
        "# We'll use one of the previously uploaded images.\n",
        "# In a real RAG scenario, you'd retrieve the image data directly from your store.\n",
        "# For demonstration, ensure 'menu maremosso temporaneo portrait.pages.png' is accessible\n",
        "# in the same directory as this notebook, or provide its full path.\n",
        "#image_file_path = \"menu maremosso temporaneo portrait.pages.png\" # Example image\n",
        "#print(f\"Loading image from: {image_file_path}\")\n",
        "#base64_image = encoded_images[0][2]\n",
        "menus = {}\n",
        "for title, typ, base_64_image in encoded_images:\n",
        "    # --- Step 2: Extract Menu Items using Gemini  need to loop through all imagers---\n",
        "    print(\"\\n--- Calling Gemini API to extract menu items ---\")\n",
        "    prompt = \"Extract all menu items and their prices from this image. Provide the output as a JSON array of objects, where each object has 'item' (string) and 'price' (number) keys. If a price is not explicitly stated, use 0.0. Do not include any introductory or concluding text, just the JSON array.\"\n",
        "    extracted_menu_data = extract_menu_from_image(base_64_image, prompt)\n",
        "    menus[title] = extracted_menu_data\n",
        "\n",
        "\n",
        "for key, men in menus.items():\n",
        "  print(f'----------------- {key}-------------')\n",
        "  from pprint import pprint\n",
        "  pprint(men)\n",
        "\n"
      ],
      "metadata": {
        "id": "vCyDjWqcA0ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Vector Store"
      ],
      "metadata": {
        "id": "Vsiil7Ovudmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb sentence-transformers\n",
        "!pip install langchain_google_vertexai\n",
        "!pip install langchain_community\n",
        "!pip install langchain\n",
        "!pip install --quiet langchain chromadb sentence-transformers openai langchain-openai"
      ],
      "metadata": {
        "id": "WimSYO5Fugq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "CHROMA_DB_PATH = \"./chroma_db_data_openai\"\n",
        "COLLECTION_NAME = \"restaurant_menus_openai\"\n",
        "# --- 1. Initialize Embedding Functions (for both populating and querying) ---\n",
        "# For populating ChromaDB directly:\n",
        "# The OpenAIEmbeddingFunction for ChromaDB's native API will automatically use OPENAI_API_KEY from os.environ\n",
        "openai_chroma_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    model_name=\"text-embedding-ada-002\" # or \"text-embedding-3-small\", \"text-embedding-3-large\"\n",
        ")\n",
        "\n",
        "# For LangChain to generate query embeddings:\n",
        "# LangChain's OpenAIEmbeddings wrapper also automatically uses OPENAI_API_KEY from os.environ\n",
        "langchain_embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\" # Match the model used for population\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "pHUjP_AQvEPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Prepare texts and metadatas for the vector store\n",
        "texts = []\n",
        "metadatas = []\n",
        "ids = [] # Unique IDs for each entry (optional but good practice)\n",
        "current_id = 0\n",
        "\n",
        "for key, restaurant_menu in menus.items():\n",
        "  print(f'----------------- {key}-------------')\n",
        "  restaurant_name = key.split('.')[0]\n",
        "  # Add Pizza Palace menu items\n",
        "  for dish in restaurant_menu:\n",
        "    text_content = f\"{dish['item']} - {dish['price']}\" # You can choose how to represent the item as text\n",
        "    texts.append(text_content)\n",
        "    metadatas.append({\"restaurant_name\": f\"{restaurant_name}\", \"item_name\": dish['item'], \"price\": dish['price']})\n",
        "    ids.append(f\"{restaurant_name}_{current_id}\")\n",
        "    current_id += 1\n",
        "\n",
        "# --- 3. Initialize Persistent ChromaDB client and collection (POPULATION PHASE) ---\n",
        "# Use PersistentClient so the data isn't lost within the Colab session\n",
        "client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
        "\n",
        "# Delete collection if it already exists (for clean re-runs during development)\n",
        "try:\n",
        "    client.delete_collection(name=COLLECTION_NAME)\n",
        "    print(f\"Deleted existing collection: {COLLECTION_NAME}\")\n",
        "except Exception as e:\n",
        "    print(f\"Collection '{COLLECTION_NAME}' did not exist or could not be deleted: {e}\")\n",
        "    pass # Collection might not exist yet, so we pass\n",
        "\n",
        "# Create the collection, passing the SentenceTransformerEmbeddingFunction instance\n",
        "collection = client.create_collection(\n",
        "    name=COLLECTION_NAME,\n",
        "    embedding_function=openai_chroma_ef # Pass the instance here\n",
        ")\n",
        "\n",
        "# Add data to the vector store (only if not already populated)\n",
        "# Checking count() can be a bit slow for very large collections, but fine for this purpose.\n",
        "if collection.count() == 0: # Check if collection is empty\n",
        "    collection.add(\n",
        "        documents=texts,\n",
        "        metadatas=metadatas,\n",
        "        ids=ids\n",
        "    )\n",
        "    print(f\"Successfully added {len(texts)} menu items to the vector store.\")\n",
        "else:\n",
        "    print(f\"Collection '{COLLECTION_NAME}' already contains {collection.count()} items. Skipping re-population.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- ChromaDB Population Complete ---\")\n",
        "print(f\"ChromaDB data stored at: {CHROMA_DB_PATH}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BYu8t9hqvcCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query for Margherita"
      ],
      "metadata": {
        "id": "2mldIu4Txpha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kicking off Langchain Pipeline"
      ],
      "metadata": {
        "id": "SqC44XWP0PFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata # Import userdata to access Colab Secrets\n",
        "\n",
        "# Retrieve the OpenAI API Key from Colab Secrets\n",
        "# The key name here must match the name you set in the Secrets tab (e.g., OPENAI_API_KEY)\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Set it as an environment variable for LangChain and OpenAI libraries to pick up\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "os.environ[\"CHROMA_OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "Z0iB3yr63Btv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- LangChain Integration (RETRIEVAL & GENERATION PHASE) ---\n",
        "\n",
        "# 4. Initialize OpenAI LLM\n",
        "try:\n",
        "    llm = ChatOpenAI(\n",
        "        model_name=\"gpt-3.5-turbo\",\n",
        "        temperature=0.3,\n",
        "    )\n",
        "    print(f\"Successfully initialized OpenAI LLM: {llm.model_name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing OpenAI LLM. Make sure your OPENAI_API_KEY is correct and accessible. Error: {e}\")\n",
        "    exit()\n",
        "\n",
        "# 5. Load your ChromaDB collection into LangChain's Chroma wrapper\n",
        "langchain_chroma_vectorstore = Chroma(\n",
        "    client=client,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    embedding_function=langchain_embeddings\n",
        ")\n",
        "print(f\"Successfully loaded ChromaDB collection '{COLLECTION_NAME}' into LangChain.\")\n",
        "\n",
        "# 6. Create a Retriever from the LangChain Chroma vector store\n",
        "retriever = langchain_chroma_vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 3}\n",
        ")\n",
        "print(\"Retriever created.\")"
      ],
      "metadata": {
        "id": "ezSgjuhQ0SVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Testing RetrievalQA Chain ---\")\n",
        "query1 = \"Which restaurants are there in gabicce ?\"\n",
        "response1 = qa_chain.invoke({\"query\": query1})\n",
        "print(f\"Question: {query1}\")\n",
        "print(f\"Answer: {response1['result']}\")\n",
        "if response1.get('source_documents'):\n",
        "    print(\"Source Documents:\")\n",
        "    for doc in response1['source_documents']:\n",
        "        print(f\"  - Content: '{doc.page_content}' | Metadata: {doc.metadata}\")\n",
        "print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "x4z98DNb6goW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QaAE-f6q0kln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fItuF0GF0ko1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Define a custom prompt template for RAG\n",
        "rag_prompt_template = \"\"\"You are a helpful assistant that answers questions about restaurant menus.\n",
        "Use the following pieces of context to answer the user's question.\n",
        "If the context does not contain the answer, state that you don't know based on the provided information.\n",
        "Provide the restaurant name, item, and price if available.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "\n",
        "RAG_PROMPT = PromptTemplate.from_template(rag_prompt_template)\n",
        "\n",
        "# 8. Build the LangChain RAG Chain\n",
        "\n",
        "# Option A: Simple RetrievalQA Chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\", # 'stuff' concatenates all retrieved documents into the prompt\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True, # Will return the documents used to generate the answer\n",
        "    chain_type_kwargs={\"prompt\": RAG_PROMPT}\n",
        ")\n",
        "print(\"RetrievalQA chain created.\")\n",
        "\n",
        "# Option B: Conversational Retrieval Chain (for multi-turn Q&A)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "conversational_qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory,\n",
        "    combine_docs_chain_kwargs={\"prompt\": RAG_PROMPT} # Use custom prompt for combining docs\n",
        ")\n",
        "print(\"ConversationalRetrievalChain created.\")\n",
        "\n",
        "# --- 9. Test your RAG application ---\n",
        "\n",
        "print(\"\\n--- Testing RetrievalQA Chain ---\")\n",
        "query1 = \"What kind of pizzas do they serve across all restaurants?\"\n",
        "response1 = qa_chain.invoke({\"query\": query1})\n",
        "print(f\"Question: {query1}\")\n",
        "print(f\"Answer: {response1['result']}\")\n",
        "if response1.get('source_documents'):\n",
        "    print(\"Source Documents:\")\n",
        "    for doc in response1['source_documents']:\n",
        "        print(f\"  - Content: '{doc.page_content}' | Metadata: {doc.metadata}\")\n",
        "print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "xgFQ8SdR0kgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Testing RetrievalQA Chain ---\")\n",
        "query1 = \"Can you list all the pasta available across all restaurants?\"\n",
        "response1 = qa_chain.invoke({\"query\": query1})\n",
        "print(f\"Question: {query1}\")\n",
        "print(f\"Answer: {response1['result']}\")\n",
        "if response1.get('source_documents'):\n",
        "    print(\"Source Documents:\")\n",
        "    for doc in response1['source_documents']:\n",
        "        print(f\"  - Content: '{doc.page_content}' | Metadata: {doc.metadata}\")\n",
        "print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "_R2bT4Wy0kvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aoc1yTTK0kyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from statistics import mean # For calculating the average\n",
        "# Now, to answer \"What is the average price of pizza margherita?\"\n",
        "\n",
        "query_item_name = \"Margherita\" # Or \"Pizza Margherita\" to be more explicit if your data varied\n",
        "# We'll query for items that are semantically similar to \"Margherita\"\n",
        "# and also filter by the specific item name metadata for precision if needed.\n",
        "\n",
        "# Step 1: Query ChromaDB to find all \"Margherita\" pizzas\n",
        "# We use a broad query text and then filter by 'item_name' metadata.\n",
        "# The 'item_name' metadata should be the exact name you want to match.\n",
        "\n",
        "# Option 1: Direct Metadata Match (most precise if 'item_name' is exact)\n",
        "# This assumes 'item_name' in your metadata is exactly \"Margherita\"\n",
        "results_margherita_direct = collection.get(\n",
        "    where={\"item_name\": \"Margherita (Pom, mozzarella)\"}, # Use the exact item name from your data\n",
        "    include=['metadatas'] # Only need the metadata to get the price\n",
        ")\n",
        "\n",
        "prices_found_direct = [m['price'] for m in results_margherita_direct['metadatas']]\n",
        "\n",
        "if prices_found_direct:\n",
        "    average_price_margherita_direct = mean(prices_found_direct)\n",
        "    print(f\"\\nAverage price of 'Margherita (Pom, mozzarella)' (direct match): £{average_price_margherita_direct:.2f}\")\n",
        "else:\n",
        "    print(f\"\\nNo exact match for 'Margherita (Pom, mozzarella)' found in the database.\")\n",
        "\n",
        "\n",
        "# Option 2: Semantic Search + Partial Item Name Filter (more flexible)\n",
        "# This might return \"Margherita Pizza\" or other variations if they existed\n",
        "# We query for \"pizza margherita\" and then filter based on if \"margherita\" is in the item name\n",
        "query_text_semantic = \"pizza margherita\"\n",
        "results_margherita_semantic = collection.query(\n",
        "    query_texts=[query_text_semantic],\n",
        "    n_results=10, # Get enough results to catch variations\n",
        "    # We can't directly use regex in `where` for text, but we can filter after retrieval.\n",
        "    # For a more robust solution within Chroma, you might need `where_document` with `$contains`\n",
        "    # if you want to search within the `documents` field.\n",
        "    # For now, let's just get the results and filter by `item_name` content in Python.\n",
        "    # We'll ensure the item_name contains \"Margherita\" or \"margherita\".\n",
        ")\n",
        "\n",
        "prices_found_semantic = []\n",
        "if results_margherita_semantic and results_margherita_semantic['metadatas'] and results_margherita_semantic['metadatas'][0]:\n",
        "    for metadata in results_margherita_semantic['metadatas'][0]:\n",
        "        # Perform a case-insensitive check for \"margherita\" in the item_name\n",
        "        if \"margherita\" in metadata.get('item_name', '').lower():\n",
        "            prices_found_semantic.append(metadata['price'])\n",
        "\n",
        "if prices_found_semantic:\n",
        "    average_price_margherita_semantic = mean(prices_found_semantic)\n",
        "    print(f\"Average price of 'Pizza Margherita' (semantic search + item name check): £{average_price_margherita_semantic:.2f}\")\n",
        "else:\n",
        "    print(f\"No items semantically related to 'Pizza Margherita' with 'margherita' in their name found.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "90r6629hxrgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Simple Model Access"
      ],
      "metadata": {
        "id": "zNNTe_22hoGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "# Replace with your actual Gemini API Key.\n",
        "# In a real environment, you'd load this securely (e.g., from environment variables).\n",
        "# For this Canvas environment, the __api_key__ variable will be provided at runtime.\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # Leave this empty, Canvas will inject the API key.\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "try:\n",
        "    # Initialize the Generative Model\n",
        "    model = genai.GenerativeModel('gemini-2.5-pro')\n",
        "\n",
        "    # Send a simple prompt\n",
        "    prompt = \"Hello, tell me something interesting.\"\n",
        "    print(f\"\\nSending a test prompt to Gemini: '{prompt}'\")\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    # Print the response to confirm functionality\n",
        "    print(\"\\n--- Gemini's Response ---\")\n",
        "    print(response.text)\n",
        "    print(\"\\nSUCCESS! Your API key appears to be working correctly with the Gemini API.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nFAILED to make a call to the Gemini API: {e}\")\n",
        "    print(\"This usually means your API key is incorrect, invalid, or you haven't enabled the Gemini API for your project.\")\n",
        "    print(\"Double-check your API key and ensure the Generative Language API is enabled in your Google Cloud project.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "x8BZaAJzVBbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofXsuGfJPRUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}