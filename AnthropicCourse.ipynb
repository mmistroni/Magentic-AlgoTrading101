{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/Magentic-AlgoTrading101/blob/main/AnthropicCourse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fThtlyg_9zY9"
      },
      "outputs": [],
      "source": [
        "# Installing dependencies\n",
        "%pip install \"anthropic[vertex]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhbUf2n3Cvzv"
      },
      "source": [
        "## Authenticate with Google\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G29RbImeCy09"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBFu1knC-CIg"
      },
      "outputs": [],
      "source": [
        "# Api client\n",
        "from anthropic import AnthropicVertex\n",
        "\n",
        "client = AnthropicVertex(region=\"global\", project_id=\"datascience-projects\")\n",
        "model = \"claude-sonnet-4@20250514\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPyGl3xb-Ldo"
      },
      "outputs": [],
      "source": [
        "message = client.messages.create(\n",
        "    model=model,\n",
        "    max_tokens=1000,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is quantum computing? Answer in one sentence\"\n",
        "        }\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvdILosiJxDn"
      },
      "outputs": [],
      "source": [
        "message.content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wC2vOLjKkhE"
      },
      "outputs": [],
      "source": [
        "message = client.messages.create(\n",
        "    model=model,\n",
        "    max_tokens=1000,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Now write antother sentence about it\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "message.content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a178f72"
      },
      "outputs": [],
      "source": [
        "def add_user_message(messages, text):\n",
        "    user_message = {\"role\": \"user\", \"content\": text}\n",
        "    messages.append(user_message)\n",
        "\n",
        "def add_assistant_message(messages, text):\n",
        "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
        "    messages.append(assistant_message)\n",
        "\n",
        "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
        "    params = {\n",
        "        \"model\": model,\n",
        "        \"max_tokens\": 1000,\n",
        "        \"messages\": messages,\n",
        "        \"temperature\" : temperature,\n",
        "        \"stop_sequences\": stop_sequences\n",
        "    }\n",
        "\n",
        "    if system:\n",
        "        params[\"system\"] = system\n",
        "\n",
        "\n",
        "    message = client.messages.create(**params)\n",
        "    return message.content[0].text\n",
        "\n",
        "\n",
        "messages = []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"\"\"\n",
        "You are a patient math tutor.\n",
        "Do not directly answer a student's questions.\n",
        "Guide them to a solution step by step.\n",
        "\"\"\"\n",
        "while True:\n",
        "    print(f'Messages:{messages}')\n",
        "    user_input = input(\">Please enter your query: \")\n",
        "    print(f'>{user_input}')\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    add_user_message(messages, user_input)\n",
        "    answer = chat(messages, system=system)\n",
        "    print(f'{answer}')\n",
        "\n",
        "    add_assistant_message(messages, answer)\n",
        "\n",
        "# Example usage of the function:\n",
        "# api_response = get_api_response_from_input()\n",
        "# print(\"API Response:\", api_response)"
      ],
      "metadata": {
        "id": "JZrggq-9ZKLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b05Df4-_CX6R"
      },
      "outputs": [],
      "source": [
        "# With system prompt\n",
        "\n",
        "add_user_message(messages, \"Write me a function that checks a string for duplicate characters\")\n",
        "answer = chat(messages)\n",
        "print(f'{answer}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b548346"
      },
      "outputs": [],
      "source": [
        "# With system prompt\n",
        "\n",
        "add_user_message(messages, \"Write me a function that checks a string for duplicate characters\")\n",
        "answer = chat(messages, system='As a python trainer, please try to be concise as possible when writing the function')\n",
        "print(f'{answer}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_user_message(messages, \"Generate one sentence movie idea\")\n",
        "answer = chat(messages, temperature=0.3)\n",
        "print(f'{answer}')\n"
      ],
      "metadata": {
        "id": "b5brBPw6sx_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Response streaming"
      ],
      "metadata": {
        "id": "KwaD5bZQJOd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages  = []\n",
        "add_user_message(\n",
        "    messages,\n",
        "    'Write one sentence  description of a fake database'\n",
        ")\n",
        "\n",
        "stream = client.messages.create(\n",
        "    model=model,\n",
        "    max_tokens=1000,\n",
        "    messages=messages,\n",
        "    stream=True\n",
        "\n",
        ")\n",
        "for event in stream:\n",
        "  print(event)"
      ],
      "metadata": {
        "id": "4G49hqvvubCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages  = []\n",
        "add_user_message(\n",
        "    messages,\n",
        "    'Write one sentence  description of a fake database'\n",
        ")\n",
        "\n",
        "with client.messages.stream(\n",
        "    model=model,\n",
        "    max_tokens=1000,\n",
        "    messages=messages\n",
        "\n",
        ") as stream:\n",
        "  for text in stream.text_stream:\n",
        "    #print(text, end=\"\")\n",
        "    pass\n",
        "print(stream.get_final_message())"
      ],
      "metadata": {
        "id": "b7HBSluwLDyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "add_user_message(messages, 'is tea or coffee better at breakfast?')\n",
        "add_assistant_message(messages, 'Neither is very good because')\n",
        "response = chat(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "iYrcCrICMP6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "add_user_message(messages, 'Count from 1 to 10')\n",
        "chat(messages, stop_sequences=['4'])"
      ],
      "metadata": {
        "id": "9BAbsFf7N3QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "add_user_message(messages, 'Generate a very short event bridge rule as json')\n",
        "add_assistant_message(messages, \"```json\")\n",
        "text = chat(messages, stop_sequences=['```'])\n",
        "text"
      ],
      "metadata": {
        "id": "F0c-ytokhLS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "json.loads(text.strip())"
      ],
      "metadata": {
        "id": "G8HTO1b3Ln42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LilKSN4jPjQc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObRq8tar1IuZvDIgekWRFp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}