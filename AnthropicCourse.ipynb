{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/Magentic-AlgoTrading101/blob/main/AnthropicCourse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fThtlyg_9zY9",
        "outputId": "82f1f7a8-5a91-4779-a0d5-d897ab86382d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic[vertex]\n",
            "  Downloading anthropic-0.68.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic[vertex]) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic[vertex]) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic[vertex]) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic[vertex]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic[vertex]) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from anthropic[vertex]) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic[vertex]) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic[vertex]) (4.15.0)\n",
            "Requirement already satisfied: google-auth<3,>=2 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[vertex]) (2.38.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic[vertex]) (3.10)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3,>=2->google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[vertex]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3,>=2->google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[vertex]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3,>=2->google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[vertex]) (4.9.1)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[vertex]) (2.32.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic[vertex]) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic[vertex]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic[vertex]) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic[vertex]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic[vertex]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic[vertex]) (0.4.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=2->google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[vertex]) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0.dev0,>=2.20.0->google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[vertex]) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0.dev0,>=2.20.0->google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[vertex]) (2.5.0)\n",
            "Downloading anthropic-0.68.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.68.0\n"
          ]
        }
      ],
      "source": [
        "# Installing dependencies\n",
        "%pip install \"anthropic[vertex]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhbUf2n3Cvzv"
      },
      "source": [
        "## Authenticate with Google\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G29RbImeCy09"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GBFu1knC-CIg"
      },
      "outputs": [],
      "source": [
        "# Api client\n",
        "from anthropic import AnthropicVertex\n",
        "\n",
        "client = AnthropicVertex(region=\"global\", project_id=\"datascience-projects\")\n",
        "model = \"claude-sonnet-4@20250514\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPyGl3xb-Ldo"
      },
      "outputs": [],
      "source": [
        "message = client.messages.create(\n",
        "    model=model,\n",
        "    max_tokens=1000,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is quantum computing? Answer in one sentence\"\n",
        "        }\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvdILosiJxDn"
      },
      "outputs": [],
      "source": [
        "message.content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6wC2vOLjKkhE",
        "outputId": "038ec9c3-b6d5-40d0-e889-0c39037f4688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'd be happy to write another sentence, but I don't see a previous sentence or topic to build on. Could you let me know what subject you'd like me to write about?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "message = client.messages.create(\n",
        "    model=model,\n",
        "    max_tokens=1000,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Now write antother sentence about it\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "message.content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0a178f72"
      },
      "outputs": [],
      "source": [
        "def add_user_message(messages, text):\n",
        "    user_message = {\"role\": \"user\", \"content\": text}\n",
        "    messages.append(user_message)\n",
        "\n",
        "def add_assistant_message(messages, text):\n",
        "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
        "    messages.append(assistant_message)\n",
        "\n",
        "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
        "    params = {\n",
        "        \"model\": model,\n",
        "        \"max_tokens\": 1000,\n",
        "        \"messages\": messages,\n",
        "        \"temperature\" : temperature,\n",
        "        \"stop_sequences\": stop_sequences\n",
        "    }\n",
        "\n",
        "    if system:\n",
        "        params[\"system\"] = system\n",
        "\n",
        "\n",
        "    message = client.messages.create(**params)\n",
        "    return message.content[0].text\n",
        "\n",
        "\n",
        "messages = []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"\"\"\n",
        "You are a patient math tutor.\n",
        "Do not directly answer a student's questions.\n",
        "Guide them to a solution step by step.\n",
        "\"\"\"\n",
        "while True:\n",
        "    print(f'Messages:{messages}')\n",
        "    user_input = input(\">Please enter your query: \")\n",
        "    print(f'>{user_input}')\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    add_user_message(messages, user_input)\n",
        "    answer = chat(messages, system=system)\n",
        "    print(f'{answer}')\n",
        "\n",
        "    add_assistant_message(messages, answer)\n",
        "\n",
        "# Example usage of the function:\n",
        "# api_response = get_api_response_from_input()\n",
        "# print(\"API Response:\", api_response)"
      ],
      "metadata": {
        "id": "JZrggq-9ZKLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b05Df4-_CX6R"
      },
      "outputs": [],
      "source": [
        "# With system prompt\n",
        "\n",
        "add_user_message(messages, \"Write me a function that checks a string for duplicate characters\")\n",
        "answer = chat(messages)\n",
        "print(f'{answer}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b548346"
      },
      "outputs": [],
      "source": [
        "# With system prompt\n",
        "\n",
        "add_user_message(messages, \"Write me a function that checks a string for duplicate characters\")\n",
        "answer = chat(messages, system='As a python trainer, please try to be concise as possible when writing the function')\n",
        "print(f'{answer}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_user_message(messages, \"Generate one sentence movie idea\")\n",
        "answer = chat(messages, temperature=0.3)\n",
        "print(f'{answer}')\n"
      ],
      "metadata": {
        "id": "b5brBPw6sx_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Response streaming"
      ],
      "metadata": {
        "id": "KwaD5bZQJOd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages  = []\n",
        "add_user_message(\n",
        "    messages,\n",
        "    'Write one sentence  description of a fake database'\n",
        ")\n",
        "\n",
        "stream = client.messages.create(\n",
        "    model=model,\n",
        "    max_tokens=1000,\n",
        "    messages=messages,\n",
        "    stream=True\n",
        "\n",
        ")\n",
        "for event in stream:\n",
        "  print(event)"
      ],
      "metadata": {
        "id": "4G49hqvvubCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages  = []\n",
        "add_user_message(\n",
        "    messages,\n",
        "    'Write one sentence  description of a fake database'\n",
        ")\n",
        "\n",
        "with client.messages.stream(\n",
        "    model=model,\n",
        "    max_tokens=1000,\n",
        "    messages=messages\n",
        "\n",
        ") as stream:\n",
        "  for text in stream.text_stream:\n",
        "    #print(text, end=\"\")\n",
        "    pass\n",
        "print(stream.get_final_message())"
      ],
      "metadata": {
        "id": "b7HBSluwLDyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "add_user_message(messages, 'is tea or coffee better at breakfast?')\n",
        "add_assistant_message(messages, 'Neither is very good because')\n",
        "response = chat(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "iYrcCrICMP6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "add_user_message(messages, 'Count from 1 to 10')\n",
        "chat(messages, stop_sequences=['4'])"
      ],
      "metadata": {
        "id": "9BAbsFf7N3QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "add_user_message(messages, 'Generate a very short event bridge rule as json')\n",
        "add_assistant_message(messages, \"```json\")\n",
        "chat(messages, stop_sequences=['```'])"
      ],
      "metadata": {
        "id": "F0c-ytokhLS7",
        "outputId": "8b27ccfe-2d78-4ce2-e17e-2e1e7d8c606b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n{\\n  \"Name\": \"OrderProcessingRule\",\\n  \"EventPattern\": {\\n    \"source\": [\"myapp.orders\"],\\n    \"detail-type\": [\"Order Placed\"]\\n  },\\n  \"Targets\": [\\n    {\\n      \"Id\": \"1\",\\n      \"Arn\": \"arn:aws:lambda:us-east-1:123456789012:function:ProcessOrder\"\\n    }\\n  ]\\n}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "id": "G8HTO1b3Ln42"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGIjllwC8xhVnmvyoxjVOI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}